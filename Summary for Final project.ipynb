{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Description:\n",
    "  Image of identification card\n",
    "  <img src=\"5_easy_001925.jpg\">  \n",
    "# Output Description:\n",
    "  Information about id number, name, date of birth, home address, current address\n",
    "  <img src=\"output.PNG\">\n",
    "# Data Description\n",
    "  Generate data by adding text to the empty id card images.\n",
    "  Images in test set will be downloaded from internet\n",
    "  Augment images by changing brightness and rotate\n",
    "  <img src=\"6_easy_004325.jpg\">\n",
    "  <img src=\"6_easy_004326.jpg\">\n",
    "  <img src=\"6_easy_004327.jpg\">\n",
    "  Training set:100.000 images\n",
    "  Validation set: 50.000 images\n",
    "  Test set: 25 images\n",
    "# Process:\n",
    "  1. Detect the area of id card in the image\n",
    "  2. Detect the area of texts in the result detected from previous step\n",
    "  3. Regconize the texts\n",
    "  4. Post process to extract information in the right format\n",
    "# Tool:\n",
    "  1. Try Mask-RCNN to detect id card\n",
    "  2. Try CRAFT(deep model focus on detect text) to detect texts. Try pretrain model and a model trained from scratch\n",
    "  3. Use Tesseract(text regconizer tool)\n",
    "  4. From coordinate and content from previous step to extract the informations.\n",
    "# Result: \n",
    "  1. Calculate mAP for using Mask-RCNN\n",
    "  2. Calculate mAP for using pretrain model and re-trained model\n",
    "  3. Count the number of correct extracted images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
